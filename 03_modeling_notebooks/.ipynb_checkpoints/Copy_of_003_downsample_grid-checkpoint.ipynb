{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXvjDReFHy0Z"
   },
   "source": [
    "* Potentially use gobbli https://github.com/rtiinternational/gobbli\n",
    "    * gobblie provides streamlit apps to perform some interactive tasks in a web browser, such as data exploration and model evaluation. \n",
    "* Check out Neural Gym GUI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MN-4BBxRHy0r"
   },
   "source": [
    "# TTD\n",
    "* run a model\n",
    "* Let's try neural net first. CNN\n",
    "* https://medium.com/@datamonsters/artificial-neural-networks-for-natural-language-processing-part-1-64ca9ebfa3b2\n",
    "* https://scikit-learn.org/stable/modules/multiclass.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUcwDaHHHy0t",
    "outputId": "92e03474-399e-46fc-c8a2-1cacad29ea24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importing Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# SKLearn Libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# SKLearn Model Libraries\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# SKLearn Metric Libraries\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "from sklearn.metrics import roc_curve, plot_roc_curve, auc, f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# Other Libraries\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QclIwFDdHy0v"
   },
   "source": [
    "_______\n",
    "# Read in Data\n",
    "_______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZmcTJNxHy0w"
   },
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv('https://raw.githubusercontent.com/JamesRonsonOp/capstone/main/data/preprocessed_ready_4_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "Vav626KVHy0x",
    "outputId": "b44c7e56-6910-428c-af8a-509f06cc9402"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varietal</th>\n",
       "      <th>description</th>\n",
       "      <th>color</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>much like regular comes rather tannic rustic e...</td>\n",
       "      <td>red</td>\n",
       "      <td>much like the regular bottling from this comes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>supple plum envelopes oaky structure supported...</td>\n",
       "      <td>red</td>\n",
       "      <td>soft supple plum envelopes an oaky structure i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>slightly reduced offers chalky tannic otherwis...</td>\n",
       "      <td>red</td>\n",
       "      <td>slightly reduced this wine offers a chalky tan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malbec</td>\n",
       "      <td>baked plum molasses balsamic vinegar cheesy ar...</td>\n",
       "      <td>red</td>\n",
       "      <td>baked plum molasses balsamic vinegar and chees...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malbec</td>\n",
       "      <td>raw aromas direct but has feel thickens over e...</td>\n",
       "      <td>red</td>\n",
       "      <td>raw black cherry aromas are direct and simple ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             varietal  ...                                             parsed\n",
       "0          Pinot Noir  ...  much like the regular bottling from this comes...\n",
       "1  Cabernet Sauvignon  ...  soft supple plum envelopes an oaky structure i...\n",
       "2  Cabernet Sauvignon  ...  slightly reduced this wine offers a chalky tan...\n",
       "3              Malbec  ...  baked plum molasses balsamic vinegar and chees...\n",
       "4              Malbec  ...  raw black cherry aromas are direct and simple ...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuzKFXa8Hy01",
    "outputId": "48a69f1d-754a-4c6b-8da0-65109b47860a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabernet Sauvignon    15199\n",
       "Pinot Noir            12193\n",
       "Chardonnay            10779\n",
       "Riesling               4759\n",
       "Syrah                  4606\n",
       "Sauvignon Blanc        4545\n",
       "Merlot                 2887\n",
       "Nebbiolo               2594\n",
       "Zinfandel              2524\n",
       "Sangiovese             2456\n",
       "Malbec                 2446\n",
       "Tempranillo            2219\n",
       "Gruner Veltliner       1196\n",
       "Pinot Grigio            978\n",
       "Gewurztraminer          937\n",
       "Viognier                919\n",
       "Grenache                605\n",
       "Glera                   596\n",
       "Chenin Blanc            543\n",
       "Albarino                434\n",
       "Garganega               244\n",
       "Name: varietal, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df['varietal'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alGMUfbbHy05"
   },
   "source": [
    "https://datatofish.com/random-rows-pandas-dataframe/\n",
    "\n",
    "https://www.kite.com/python/answers/how-to-create-an-empty-dataframe-with-column-names-in-python\n",
    "\n",
    "https://stats.stackexchange.com/questions/227088/when-should-i-balance-classes-in-a-training-data-set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FvsJ11xEHy08"
   },
   "outputs": [],
   "source": [
    "def mass_downsampler(df, col_name, num_samples):\n",
    "    \n",
    "    old_df = pd.DataFrame(columns = df.columns)\n",
    "    \n",
    "    \n",
    "    # iterate through unique class labels in column\n",
    "    for class_name in df[col_name].unique():\n",
    "        \n",
    "        # create a sliced DF of just the class specified\n",
    "        new_df = df[df[col_name] == class_name]\n",
    "        \n",
    "        \n",
    "        # if new df less than num_samples add to old_df\n",
    "        if new_df.shape[0] <= num_samples:\n",
    "            old_df = pd.concat([old_df, new_df])\n",
    "            \n",
    "        # if column has more than num_samples then downsample it.     \n",
    "        if new_df.shape[0] > num_samples:\n",
    "            \n",
    "            # Create a sliced DF for each label \n",
    "            # Sample from sliced DF for num_samples number of times\n",
    "            down_df = new_df.sample(n = num_samples)\n",
    "           \n",
    "            # concat down_df to old_df's\n",
    "            old_df = pd.concat([old_df, down_df])\n",
    "        \n",
    "\n",
    "    return old_df    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8SrYgRKHy09"
   },
   "outputs": [],
   "source": [
    "down_df = mass_downsampler(wine_df, 'varietal', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08xQiIYqHy09",
    "outputId": "d10ee377-7eb0-4297-c72b-ce563dff17d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Viognier              300\n",
       "Pinot Noir            300\n",
       "Chenin Blanc          300\n",
       "Gruner Veltliner      300\n",
       "Glera                 300\n",
       "Grenache              300\n",
       "Nebbiolo              300\n",
       "Merlot                300\n",
       "Tempranillo           300\n",
       "Albarino              300\n",
       "Gewurztraminer        300\n",
       "Chardonnay            300\n",
       "Pinot Grigio          300\n",
       "Sangiovese            300\n",
       "Cabernet Sauvignon    300\n",
       "Malbec                300\n",
       "Sauvignon Blanc       300\n",
       "Riesling              300\n",
       "Zinfandel             300\n",
       "Syrah                 300\n",
       "Garganega             244\n",
       "Name: varietal, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_df['varietal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40qO81SdHy09",
    "outputId": "97a77f2a-6329-47fa-ed8e-d7d40c4d4efe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "varietal       0\n",
       "description    0\n",
       "color          0\n",
       "parsed         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "YeObKG9_Hy0-",
    "outputId": "3ad6de32-63e8-4cd0-8eb7-fd560920fc9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varietal</th>\n",
       "      <th>description</th>\n",
       "      <th>color</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34369</th>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>red</td>\n",
       "      <td>this wine is all wood with no promise of fruit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 varietal  ...                                          parsed\n",
       "34369  Cabernet Sauvignon  ...  this wine is all wood with no promise of fruit\n",
       "\n",
       "[1 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df[wine_df['description'].isnull() == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urYpXDaFHy0-",
    "outputId": "8e672017-0592-4d0c-94ed-2e467ca1882d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "varietal       0\n",
       "description    0\n",
       "color          0\n",
       "parsed         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# locating the above null value\n",
    "wine_df.loc[34369,  'parsed']\n",
    "\n",
    "# dropping it\n",
    "wine_df.drop(34369, inplace = True)\n",
    "\n",
    "# checking to see if it worked\n",
    "wine_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wE8ANYvaHy0-"
   },
   "source": [
    "___________\n",
    "# Class Distribution Analysis for MultiClass Target\n",
    "* I will be using the 'varietal' feature as my targets\n",
    "* In the following steps I will create a DF that is grouped by target column, I will create numerical labels for these targets and I will plot the distribution of the classes.\n",
    "___________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycXz7KnKHy0_"
   },
   "outputs": [],
   "source": [
    "# defining a function that takes in a df, a column list that includes target column\n",
    "# and a column that can be counted to determine value counts. \n",
    "# it returns a df with value counts and percentages of value counts\n",
    "# it also returns a plot of class imbalances.\n",
    "\n",
    "def class_balance_analyzer(df, target_col, count_col):\n",
    "    \n",
    "    # creating a df that groups by target classes\n",
    "    targets = df[[target_col, \n",
    "                  count_col]].groupby(target_col, as_index = False).count()\n",
    "    \n",
    "    # sorting target values by count descending\n",
    "    targets.sort_values(count_col, ascending = True, inplace = True)\n",
    "    \n",
    "    # renaming column for clarity\n",
    "    targets.rename(columns = {count_col: 'count'}, inplace = True)\n",
    "    \n",
    "    # resetting index\n",
    "    targets.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    targets['percent'] = round(targets['count'] / targets['count'].sum() * 100, 2)\n",
    "    \n",
    "    plt.barh(targets[target_col], targets['count'])\n",
    "    \n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.ylabel('Classes')\n",
    "    plt.xlabel('Number of Samples')\n",
    "    \n",
    "    plt.show();\n",
    "    \n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 971
    },
    "id": "duZ_OuNxHy1A",
    "outputId": "57531b31-eb36-4031-ede6-a6e999044a1f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varietal</th>\n",
       "      <th>count</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Garganega</td>\n",
       "      <td>244</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albarino</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempranillo</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Syrah</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sangiovese</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Riesling</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pinot Grigio</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nebbiolo</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Merlot</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Malbec</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gruner Veltliner</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Grenache</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Glera</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gewurztraminer</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chenin Blanc</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Viognier</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Zinfandel</td>\n",
       "      <td>300</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              varietal  count  percent\n",
       "0            Garganega    244     3.91\n",
       "1             Albarino    300     4.80\n",
       "2          Tempranillo    300     4.80\n",
       "3                Syrah    300     4.80\n",
       "4      Sauvignon Blanc    300     4.80\n",
       "5           Sangiovese    300     4.80\n",
       "6             Riesling    300     4.80\n",
       "7           Pinot Noir    300     4.80\n",
       "8         Pinot Grigio    300     4.80\n",
       "9             Nebbiolo    300     4.80\n",
       "10              Merlot    300     4.80\n",
       "11              Malbec    300     4.80\n",
       "12    Gruner Veltliner    300     4.80\n",
       "13            Grenache    300     4.80\n",
       "14               Glera    300     4.80\n",
       "15      Gewurztraminer    300     4.80\n",
       "16        Chenin Blanc    300     4.80\n",
       "17          Chardonnay    300     4.80\n",
       "18  Cabernet Sauvignon    300     4.80\n",
       "19            Viognier    300     4.80\n",
       "20           Zinfandel    300     4.80"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = class_balance_analyzer(down_df, 'varietal', 'description')\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9cJvnWyHy1B"
   },
   "source": [
    "**Analysis of Class Distributions Plot**\n",
    "\n",
    "* There is some serious class imbalance within these 20 classes. I will need to do quite a bit of work to get them to be balanced.\n",
    "\n",
    "**Approaches I will attempt**\n",
    "\n",
    "* First approach is to eliminate values from larger classes in order to bring the data more into balance. \n",
    "* Second approach is to consider bootstrapping each column for the purpose of increasing the sample sizes. There are a number of ways to do this.  \n",
    "    * SMOTE algorithm. https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/ \n",
    "    * Cost-Sensitive Learning For Imbalanced Classification. https://machinelearningmastery.com/cost-sensitive-learning-for-imbalanced-classification/\n",
    "    * Cost_Sensitive Logistic Rgression for Imbalanced Classification https://machinelearningmastery.com/cost-sensitive-logistic-regression/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Evwnhq0vHy1C"
   },
   "source": [
    "__________\n",
    "# Create Target and Predictor Variables\n",
    "_________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sK6_E6UyHy1L"
   },
   "outputs": [],
   "source": [
    "X = down_df['description']\n",
    "# Creating Multi-Class Targets\n",
    "y_multi = down_df['varietal']\n",
    "# Creating binary targets for exploration purposes. \n",
    "y = down_df['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n00fDTzaHy1M"
   },
   "outputs": [],
   "source": [
    "# Binarizing binary targets\n",
    "y = y.map({'white': 0, 'red': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CQz2Tj6XHy1N",
    "outputId": "1259a92c-bedc-4d7e-afb7-ea7f862f8dfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Variables Shape: (6244,)\n",
      "Target Variables Shape: (6244,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Feature Variables Shape: {X.shape}')\n",
    "print(f'Target Variables Shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQyRxdo9Hy1O"
   },
   "source": [
    "# Baseline Model For Multi-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2NMn-epYHy1P",
    "outputId": "abf8955e-6a61-404d-85cd-59581a62f1f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Viognier              0.048046\n",
       "Pinot Noir            0.048046\n",
       "Chenin Blanc          0.048046\n",
       "Gruner Veltliner      0.048046\n",
       "Glera                 0.048046\n",
       "Grenache              0.048046\n",
       "Nebbiolo              0.048046\n",
       "Merlot                0.048046\n",
       "Tempranillo           0.048046\n",
       "Albarino              0.048046\n",
       "Gewurztraminer        0.048046\n",
       "Chardonnay            0.048046\n",
       "Pinot Grigio          0.048046\n",
       "Sangiovese            0.048046\n",
       "Cabernet Sauvignon    0.048046\n",
       "Malbec                0.048046\n",
       "Sauvignon Blanc       0.048046\n",
       "Riesling              0.048046\n",
       "Zinfandel             0.048046\n",
       "Syrah                 0.048046\n",
       "Garganega             0.039078\n",
       "Name: varietal, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bC6YqMxMHy1Q"
   },
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HvOpHR5sHy1Q"
   },
   "outputs": [],
   "source": [
    "# encoding y_multi\n",
    "y_multi = LabelEncoder().fit_transform(y_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZjfSGahHy1Q"
   },
   "outputs": [],
   "source": [
    "def encode_workflow(target_series):\n",
    "    \n",
    "    # Instantiate LabelEncoder(), fit it and transform it.\n",
    "    target_series = LabelEncoder().fit_transform(target_series)\n",
    "    \n",
    "    \n",
    "    # create a df of target labels\n",
    "    encoded = pd.DataFrame(target_series) \n",
    "    \n",
    "    # create a df that contains only the encoded df's value_counts()\n",
    "    label_counts = encoded[0].value_counts()\n",
    "    \n",
    "    # reset the index so the class labels are no longer the index\n",
    "    label_counts = label_counts.reset_index()\n",
    "    \n",
    "    # rename columns for clarity\n",
    "    label_counts.rename(columns = {'index': 'encoded_labels', 0: 'count'}, inplace = True)\n",
    "    \n",
    "    return label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "qYTDj9x7Hy1Q",
    "outputId": "b16b4a44-e653-4002-b046-f1ef82610266"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>encoded_labels</th>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0    1    2    3    4    5   ...   15   16   17   18   19   20\n",
       "encoded_labels   19   15    8   12   16   20  ...   18    3    7   11    0    4\n",
       "count           300  300  300  300  300  300  ...  300  300  300  300  300  244\n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating label_counts df by calling the encode_workflow custom function\n",
    "label_counts = encode_workflow(y_multi)\n",
    "\n",
    "# Viewing label_counts df that was created above\n",
    "# Transposing it to shorten workbook\n",
    "label_counts.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o996cf4JHy1R"
   },
   "source": [
    "# Train / Test / Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKp4UQ1IHy1R"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_multi,\n",
    "                                                   test_size = .33, \n",
    "                                                   stratify = y, \n",
    "                                                   random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBaZO-oeHy1R",
    "outputId": "692ea76e-7de5-4c91-fd0a-ff449c525be9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "722928"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking computational size of X_train\n",
    "import sys\n",
    "sys.getsizeof(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2Zmqf9wHy1R"
   },
   "source": [
    "# Grid Searching Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttVlMw7XHy1R"
   },
   "outputs": [],
   "source": [
    "## creating a list of our two chosen vectorizers to iterate through in our grid search\n",
    "vectorizer = [CountVectorizer(), TfidfVectorizer()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQH1yqbrHy1S"
   },
   "outputs": [],
   "source": [
    "## creating variables to accept tuning parameters\n",
    "max_feat = [300, 500]  \n",
    "ngram_range = [(1, 3), (1, 2)] \n",
    "stop_words = [None, 'english'] \n",
    "max_df = [0.9, 0.8] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0A9_uGLCHy1S"
   },
   "outputs": [],
   "source": [
    "# ## creating any empty results list to capture our cv_results_ at the end of each iteration\n",
    "# results = []\n",
    "\n",
    "# ## looping through both vectorizers\n",
    "# for vect in vectorizer:\n",
    "    \n",
    "#     #### Pipeline for our Vectorizer and Classifier Models ####\n",
    "#     pipeline = Pipeline([\n",
    "#         ('vect', vect),\n",
    "#         ('clf', LogisticRegression())])\n",
    "    \n",
    "#     instantiations = [ #### Beginning of Instantiations List ####\n",
    "#         {\n",
    "#             ### Log Reg Vect Hyperparameters ###\n",
    "            \n",
    "#             'vect__max_features': max_feat,\n",
    "#             'vect__stop_words': stop_words,\n",
    "#             'vect__ngram_range': ngram_range,\n",
    "#             'vect__max_df': max_df,\n",
    "            \n",
    "#             ## Instantiate Log Reg and Hyperparamaters\n",
    "#             'clf': (LogisticRegression(solver='liblinear'), ), ## setting our first classifier model\n",
    "#             'clf__penalty': ('l1', 'l2'),\n",
    "#             'clf__C': (.5, 1.0), \n",
    "#         }, \n",
    "#     #######\n",
    "#         {\n",
    "            \n",
    "#             ### Multinomial Bayes Vect Hyperparameters ###\n",
    "#             'vect__max_features': max_feat,\n",
    "#             'vect__stop_words': stop_words,\n",
    "#             'vect__ngram_range': ngram_range,\n",
    "#             'vect__max_df': max_df,\n",
    "            \n",
    "#             ## Instantiate Mulinomial NB and Hyperparamters ##\n",
    "#             'clf': (MultinomialNB(), ),  \n",
    "#             'clf__alpha': (.5, 1.0)\n",
    "#         },\n",
    "#     #######   \n",
    "#         {\n",
    "#             ### SVC Vect Hyperparameters ###\n",
    "#             'vect__max_features': max_feat,\n",
    "#             'vect__stop_words': stop_words,\n",
    "#             'vect__ngram_range': ngram_range,\n",
    "#             'vect__max_df': max_df,\n",
    "            \n",
    "#             ## KNN Instantiation and Hyperparameters\n",
    "#             'clf': (KNeighborsClassifier(), ),\n",
    "#             'clf__n_neighbors': (5 , 10),\n",
    "#             'clf__weights': ('uniform', 'distance')\n",
    "#         },\n",
    "#     #######  \n",
    "#         {\n",
    "#             ### RandomForestClassifier Vect Hyperparameters ###\n",
    "#             'vect__max_features': max_feat,\n",
    "#             'vect__stop_words': stop_words,\n",
    "#             'vect__ngram_range': ngram_range,\n",
    "#             'vect__max_df': max_df,\n",
    "            \n",
    "#             ## Instantiate RandomForestClassifier ##\n",
    "#             'clf': (RandomForestClassifier(n_estimators=50, min_samples_split=5), ),\n",
    "#         },\n",
    "#     #######\n",
    "#         {\n",
    "#             ### Voting Classifier Vect Hyperparameters ###\n",
    "#             'vect__max_features': max_feat,\n",
    "#             'vect__stop_words': stop_words,\n",
    "#             'vect__ngram_range': ngram_range,\n",
    "#             'vect__max_df': max_df,\n",
    "            \n",
    "#             ## Instantiating Ensemble Voting Classifier ##\n",
    "#             'clf': (VotingClassifier(estimators=[('lr', LogisticRegression()), \n",
    "#                                                  ('rf', RandomForestClassifier()), \n",
    "#                                                  ('mnb', MultinomialNB()), \n",
    "#                                                  ('svc', KNeighborsClassifier())],                                           \n",
    "#                                             voting='hard'), )\n",
    "#         }    \n",
    "#                     ] #### end of instantiations list ####\n",
    "    \n",
    "    \n",
    "#     #### Grid Search ####\n",
    "    \n",
    "#     grid_search = GridSearchCV(pipeline, \n",
    "#                                instantiations,\n",
    "#                                cv=3,\n",
    "#                                n_jobs=-1,\n",
    "#                                verbose=3,\n",
    "#                                return_train_score=True)\n",
    "    \n",
    "#     #### Output Results ####\n",
    "    \n",
    "#     ## running an if statement to print the type of vectorizer used\n",
    "#     if vect == vectorizer[0]:\n",
    "#         vect_string = \"CountVectorizer\"\n",
    "    \n",
    "#     else:\n",
    "#         vect_string = \"Tf-IDF Vectorizer\"\n",
    "    \n",
    "#     ## fitting our model and printing our best scores and parameters\n",
    "#     grid_search.fit(X_train, y_train)\n",
    "#     print(f'''Best score for {vect_string} is: \n",
    "#     {round(grid_search.best_score_, 4)}\n",
    "#     ''')\n",
    "#     print(grid_search.best_params_)\n",
    "#     print(\"\")\n",
    "    \n",
    "#     ## appending our cv_results_ to the end of results\n",
    "#     results.append(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDcOLsNUHy1a"
   },
   "outputs": [],
   "source": [
    "# results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "# results_df['score_diff'] = results_df['mean_test_score'] - results_df['mean_train_score']\n",
    "# results_df['high_plus_diff'] = results_df['mean_test_score'] + results_df['score_diff']\n",
    "# results_df = results_df.sort_values('high_plus_diff', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vKqIt0jjHy1d",
    "outputId": "2ad84fde-0070-4ac5-8194-19a316d02f43"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__penalty</th>\n",
       "      <th>param_vect__max_df</th>\n",
       "      <th>param_vect__max_features</th>\n",
       "      <th>param_vect__ngram_range</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>score_diff</th>\n",
       "      <th>high_plus_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.701761</td>\n",
       "      <td>0.007231</td>\n",
       "      <td>0.114018</td>\n",
       "      <td>0.023355</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306479</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>113</td>\n",
       "      <td>0.373745</td>\n",
       "      <td>0.377196</td>\n",
       "      <td>0.371818</td>\n",
       "      <td>0.374253</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>-0.067774</td>\n",
       "      <td>0.238705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.601833</td>\n",
       "      <td>0.065945</td>\n",
       "      <td>0.122401</td>\n",
       "      <td>0.011323</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306479</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>113</td>\n",
       "      <td>0.373745</td>\n",
       "      <td>0.377555</td>\n",
       "      <td>0.371818</td>\n",
       "      <td>0.374372</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>-0.067894</td>\n",
       "      <td>0.238585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.836362</td>\n",
       "      <td>0.054492</td>\n",
       "      <td>0.179583</td>\n",
       "      <td>0.050107</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306001</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>115</td>\n",
       "      <td>0.372669</td>\n",
       "      <td>0.377913</td>\n",
       "      <td>0.372894</td>\n",
       "      <td>0.374492</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>-0.068491</td>\n",
       "      <td>0.237509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.219618</td>\n",
       "      <td>0.083486</td>\n",
       "      <td>0.160097</td>\n",
       "      <td>0.036570</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306001</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>115</td>\n",
       "      <td>0.372669</td>\n",
       "      <td>0.377913</td>\n",
       "      <td>0.372894</td>\n",
       "      <td>0.374492</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>-0.068491</td>\n",
       "      <td>0.237509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.697246</td>\n",
       "      <td>0.050164</td>\n",
       "      <td>0.106463</td>\n",
       "      <td>0.005930</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301936</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>123</td>\n",
       "      <td>0.375179</td>\n",
       "      <td>0.376120</td>\n",
       "      <td>0.376120</td>\n",
       "      <td>0.375807</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>-0.073870</td>\n",
       "      <td>0.228066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1.678925</td>\n",
       "      <td>0.048984</td>\n",
       "      <td>1.009266</td>\n",
       "      <td>0.120788</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219462</td>\n",
       "      <td>0.031861</td>\n",
       "      <td>179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998924</td>\n",
       "      <td>0.999283</td>\n",
       "      <td>0.999402</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>-0.779940</td>\n",
       "      <td>-0.560478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1.304747</td>\n",
       "      <td>0.078211</td>\n",
       "      <td>0.735336</td>\n",
       "      <td>0.046192</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218028</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>183</td>\n",
       "      <td>0.998924</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>-0.780418</td>\n",
       "      <td>-0.562389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1.657034</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>1.188079</td>\n",
       "      <td>0.070651</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218028</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>183</td>\n",
       "      <td>0.998924</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>-0.780418</td>\n",
       "      <td>-0.562389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.736727</td>\n",
       "      <td>0.018860</td>\n",
       "      <td>0.617709</td>\n",
       "      <td>0.035881</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214680</td>\n",
       "      <td>0.006798</td>\n",
       "      <td>187</td>\n",
       "      <td>0.998924</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>-0.783766</td>\n",
       "      <td>-0.569085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.753107</td>\n",
       "      <td>0.045474</td>\n",
       "      <td>0.711773</td>\n",
       "      <td>0.082492</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214680</td>\n",
       "      <td>0.006798</td>\n",
       "      <td>187</td>\n",
       "      <td>0.998924</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>-0.783766</td>\n",
       "      <td>-0.569085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7         0.701761      0.007231         0.114018        0.023355   \n",
       "15        0.601833      0.065945         0.122401        0.011323   \n",
       "5         0.836362      0.054492         0.179583        0.050107   \n",
       "13        1.219618      0.083486         0.160097        0.036570   \n",
       "6         0.697246      0.050164         0.106463        0.005930   \n",
       "..             ...           ...              ...             ...   \n",
       "120       1.678925      0.048984         1.009266        0.120788   \n",
       "113       1.304747      0.078211         0.735336        0.046192   \n",
       "121       1.657034      0.082300         1.188079        0.070651   \n",
       "115       0.736727      0.018860         0.617709        0.035881   \n",
       "123       0.753107      0.045474         0.711773        0.082492   \n",
       "\n",
       "                                  param_clf param_clf__C param_clf__penalty  \\\n",
       "7    LogisticRegression(solver='liblinear')          0.5                 l1   \n",
       "15   LogisticRegression(solver='liblinear')          0.5                 l1   \n",
       "5    LogisticRegression(solver='liblinear')          0.5                 l1   \n",
       "13   LogisticRegression(solver='liblinear')          0.5                 l1   \n",
       "6    LogisticRegression(solver='liblinear')          0.5                 l1   \n",
       "..                                      ...          ...                ...   \n",
       "120                  KNeighborsClassifier()          NaN                NaN   \n",
       "113                  KNeighborsClassifier()          NaN                NaN   \n",
       "121                  KNeighborsClassifier()          NaN                NaN   \n",
       "115                  KNeighborsClassifier()          NaN                NaN   \n",
       "123                  KNeighborsClassifier()          NaN                NaN   \n",
       "\n",
       "    param_vect__max_df param_vect__max_features param_vect__ngram_range  ...  \\\n",
       "7                  0.9                      500                  (1, 2)  ...   \n",
       "15                 0.8                      500                  (1, 2)  ...   \n",
       "5                  0.9                      500                  (1, 3)  ...   \n",
       "13                 0.8                      500                  (1, 3)  ...   \n",
       "6                  0.9                      500                  (1, 2)  ...   \n",
       "..                 ...                      ...                     ...  ...   \n",
       "120                0.8                      300                  (1, 3)  ...   \n",
       "113                0.9                      300                  (1, 3)  ...   \n",
       "121                0.8                      300                  (1, 3)  ...   \n",
       "115                0.9                      300                  (1, 2)  ...   \n",
       "123                0.8                      300                  (1, 2)  ...   \n",
       "\n",
       "    mean_test_score std_test_score rank_test_score split0_train_score  \\\n",
       "7          0.306479       0.003600             113           0.373745   \n",
       "15         0.306479       0.003600             113           0.373745   \n",
       "5          0.306001       0.004124             115           0.372669   \n",
       "13         0.306001       0.004124             115           0.372669   \n",
       "6          0.301936       0.006444             123           0.375179   \n",
       "..              ...            ...             ...                ...   \n",
       "120        0.219462       0.031861             179           1.000000   \n",
       "113        0.218028       0.009655             183           0.998924   \n",
       "121        0.218028       0.009655             183           0.998924   \n",
       "115        0.214680       0.006798             187           0.998924   \n",
       "123        0.214680       0.006798             187           0.998924   \n",
       "\n",
       "    split1_train_score  split2_train_score  mean_train_score  std_train_score  \\\n",
       "7             0.377196            0.371818          0.374253         0.002225   \n",
       "15            0.377555            0.371818          0.374372         0.002384   \n",
       "5             0.377913            0.372894          0.374492         0.002421   \n",
       "13            0.377913            0.372894          0.374492         0.002421   \n",
       "6             0.376120            0.376120          0.375807         0.000444   \n",
       "..                 ...                 ...               ...              ...   \n",
       "120           0.998924            0.999283          0.999402         0.000447   \n",
       "113           0.998207            0.998207          0.998446         0.000338   \n",
       "121           0.998207            0.998207          0.998446         0.000338   \n",
       "115           0.998207            0.998207          0.998446         0.000338   \n",
       "123           0.998207            0.998207          0.998446         0.000338   \n",
       "\n",
       "     score_diff  high_plus_diff  \n",
       "7     -0.067774        0.238705  \n",
       "15    -0.067894        0.238585  \n",
       "5     -0.068491        0.237509  \n",
       "13    -0.068491        0.237509  \n",
       "6     -0.073870        0.228066  \n",
       "..          ...             ...  \n",
       "120   -0.779940       -0.560478  \n",
       "113   -0.780418       -0.562389  \n",
       "121   -0.780418       -0.562389  \n",
       "115   -0.783766       -0.569085  \n",
       "123   -0.783766       -0.569085  \n",
       "\n",
       "[192 rows x 28 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XjWcv4bpHy1e",
    "outputId": "09a14637-bdfe-4da2-f07f-f1075c322142"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__penalty</th>\n",
       "      <th>param_vect__max_df</th>\n",
       "      <th>param_vect__max_features</th>\n",
       "      <th>param_vect__ngram_range</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>score_diff</th>\n",
       "      <th>high_plus_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.701761</td>\n",
       "      <td>0.007231</td>\n",
       "      <td>0.114018</td>\n",
       "      <td>0.023355</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306479</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>113</td>\n",
       "      <td>0.373745</td>\n",
       "      <td>0.377196</td>\n",
       "      <td>0.371818</td>\n",
       "      <td>0.374253</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>-0.067774</td>\n",
       "      <td>0.238705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.601833</td>\n",
       "      <td>0.065945</td>\n",
       "      <td>0.122401</td>\n",
       "      <td>0.011323</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306479</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>113</td>\n",
       "      <td>0.373745</td>\n",
       "      <td>0.377555</td>\n",
       "      <td>0.371818</td>\n",
       "      <td>0.374372</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>-0.067894</td>\n",
       "      <td>0.238585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.836362</td>\n",
       "      <td>0.054492</td>\n",
       "      <td>0.179583</td>\n",
       "      <td>0.050107</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306001</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>115</td>\n",
       "      <td>0.372669</td>\n",
       "      <td>0.377913</td>\n",
       "      <td>0.372894</td>\n",
       "      <td>0.374492</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>-0.068491</td>\n",
       "      <td>0.237509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.219618</td>\n",
       "      <td>0.083486</td>\n",
       "      <td>0.160097</td>\n",
       "      <td>0.036570</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306001</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>115</td>\n",
       "      <td>0.372669</td>\n",
       "      <td>0.377913</td>\n",
       "      <td>0.372894</td>\n",
       "      <td>0.374492</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>-0.068491</td>\n",
       "      <td>0.237509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.697246</td>\n",
       "      <td>0.050164</td>\n",
       "      <td>0.106463</td>\n",
       "      <td>0.005930</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301936</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>123</td>\n",
       "      <td>0.375179</td>\n",
       "      <td>0.376120</td>\n",
       "      <td>0.376120</td>\n",
       "      <td>0.375807</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>-0.073870</td>\n",
       "      <td>0.228066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1.678925</td>\n",
       "      <td>0.048984</td>\n",
       "      <td>1.009266</td>\n",
       "      <td>0.120788</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219462</td>\n",
       "      <td>0.031861</td>\n",
       "      <td>179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998924</td>\n",
       "      <td>0.999283</td>\n",
       "      <td>0.999402</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>-0.779940</td>\n",
       "      <td>-0.560478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1.304747</td>\n",
       "      <td>0.078211</td>\n",
       "      <td>0.735336</td>\n",
       "      <td>0.046192</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218028</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>183</td>\n",
       "      <td>0.998924</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>-0.780418</td>\n",
       "      <td>-0.562389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1.657034</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>1.188079</td>\n",
       "      <td>0.070651</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218028</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>183</td>\n",
       "      <td>0.998924</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>-0.780418</td>\n",
       "      <td>-0.562389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.736727</td>\n",
       "      <td>0.018860</td>\n",
       "      <td>0.617709</td>\n",
       "      <td>0.035881</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214680</td>\n",
       "      <td>0.006798</td>\n",
       "      <td>187</td>\n",
       "      <td>0.998924</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>-0.783766</td>\n",
       "      <td>-0.569085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.753107</td>\n",
       "      <td>0.045474</td>\n",
       "      <td>0.711773</td>\n",
       "      <td>0.082492</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214680</td>\n",
       "      <td>0.006798</td>\n",
       "      <td>187</td>\n",
       "      <td>0.998924</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>-0.783766</td>\n",
       "      <td>-0.569085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7         0.701761      0.007231         0.114018        0.023355   \n",
       "15        0.601833      0.065945         0.122401        0.011323   \n",
       "5         0.836362      0.054492         0.179583        0.050107   \n",
       "13        1.219618      0.083486         0.160097        0.036570   \n",
       "6         0.697246      0.050164         0.106463        0.005930   \n",
       "..             ...           ...              ...             ...   \n",
       "120       1.678925      0.048984         1.009266        0.120788   \n",
       "113       1.304747      0.078211         0.735336        0.046192   \n",
       "121       1.657034      0.082300         1.188079        0.070651   \n",
       "115       0.736727      0.018860         0.617709        0.035881   \n",
       "123       0.753107      0.045474         0.711773        0.082492   \n",
       "\n",
       "                                  param_clf param_clf__C param_clf__penalty  \\\n",
       "7    LogisticRegression(solver='liblinear')          0.5                 l1   \n",
       "15   LogisticRegression(solver='liblinear')          0.5                 l1   \n",
       "5    LogisticRegression(solver='liblinear')          0.5                 l1   \n",
       "13   LogisticRegression(solver='liblinear')          0.5                 l1   \n",
       "6    LogisticRegression(solver='liblinear')          0.5                 l1   \n",
       "..                                      ...          ...                ...   \n",
       "120                  KNeighborsClassifier()          NaN                NaN   \n",
       "113                  KNeighborsClassifier()          NaN                NaN   \n",
       "121                  KNeighborsClassifier()          NaN                NaN   \n",
       "115                  KNeighborsClassifier()          NaN                NaN   \n",
       "123                  KNeighborsClassifier()          NaN                NaN   \n",
       "\n",
       "    param_vect__max_df param_vect__max_features param_vect__ngram_range  ...  \\\n",
       "7                  0.9                      500                  (1, 2)  ...   \n",
       "15                 0.8                      500                  (1, 2)  ...   \n",
       "5                  0.9                      500                  (1, 3)  ...   \n",
       "13                 0.8                      500                  (1, 3)  ...   \n",
       "6                  0.9                      500                  (1, 2)  ...   \n",
       "..                 ...                      ...                     ...  ...   \n",
       "120                0.8                      300                  (1, 3)  ...   \n",
       "113                0.9                      300                  (1, 3)  ...   \n",
       "121                0.8                      300                  (1, 3)  ...   \n",
       "115                0.9                      300                  (1, 2)  ...   \n",
       "123                0.8                      300                  (1, 2)  ...   \n",
       "\n",
       "    mean_test_score std_test_score rank_test_score split0_train_score  \\\n",
       "7          0.306479       0.003600             113           0.373745   \n",
       "15         0.306479       0.003600             113           0.373745   \n",
       "5          0.306001       0.004124             115           0.372669   \n",
       "13         0.306001       0.004124             115           0.372669   \n",
       "6          0.301936       0.006444             123           0.375179   \n",
       "..              ...            ...             ...                ...   \n",
       "120        0.219462       0.031861             179           1.000000   \n",
       "113        0.218028       0.009655             183           0.998924   \n",
       "121        0.218028       0.009655             183           0.998924   \n",
       "115        0.214680       0.006798             187           0.998924   \n",
       "123        0.214680       0.006798             187           0.998924   \n",
       "\n",
       "    split1_train_score  split2_train_score  mean_train_score  std_train_score  \\\n",
       "7             0.377196            0.371818          0.374253         0.002225   \n",
       "15            0.377555            0.371818          0.374372         0.002384   \n",
       "5             0.377913            0.372894          0.374492         0.002421   \n",
       "13            0.377913            0.372894          0.374492         0.002421   \n",
       "6             0.376120            0.376120          0.375807         0.000444   \n",
       "..                 ...                 ...               ...              ...   \n",
       "120           0.998924            0.999283          0.999402         0.000447   \n",
       "113           0.998207            0.998207          0.998446         0.000338   \n",
       "121           0.998207            0.998207          0.998446         0.000338   \n",
       "115           0.998207            0.998207          0.998446         0.000338   \n",
       "123           0.998207            0.998207          0.998446         0.000338   \n",
       "\n",
       "     score_diff  high_plus_diff  \n",
       "7     -0.067774        0.238705  \n",
       "15    -0.067894        0.238585  \n",
       "5     -0.068491        0.237509  \n",
       "13    -0.068491        0.237509  \n",
       "6     -0.073870        0.228066  \n",
       "..          ...             ...  \n",
       "120   -0.779940       -0.560478  \n",
       "113   -0.780418       -0.562389  \n",
       "121   -0.780418       -0.562389  \n",
       "115   -0.783766       -0.569085  \n",
       "123   -0.783766       -0.569085  \n",
       "\n",
       "[192 rows x 28 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results_df.sort_values('score_diff', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3EWLjWXHy1e"
   },
   "outputs": [],
   "source": [
    "X = wine_df['description']\n",
    "y = wine_df['varietal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJulMzbBHy1f"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size = .33, \n",
    "                                                   stratify = y, \n",
    "                                                   random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WZUs4ZkHy1f"
   },
   "source": [
    "# Vectorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoMdZOjOHy1f"
   },
   "source": [
    "'clf': MultinomialNB(), 'clf__alpha': 1.0, 'vect__max_df': 0.9, 'vect__max_features': 500, 'vect__ngram_range': (1, 3), 'vect__stop_words': 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvaTlcIBHy1f",
    "outputId": "ee545554-6cd6-481a-e7b4-7a0693909014"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=0.9, max_features=500, min_df=1,\n",
       "                ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate CountVectorizer()\n",
    "cvec = CountVectorizer(max_df = .9, max_features = 500, \n",
    "                       ngram_range = (1,3), stop_words = 'english')\n",
    "\n",
    "# fit CountVectorizer()\n",
    "cvec.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGmewI2BHy1g"
   },
   "outputs": [],
   "source": [
    "# Transform the corpus on training data\n",
    "X_train = cvec.transform(X_train)\n",
    "X_test = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59g76X_vHy1e"
   },
   "source": [
    "# Multinomial Naive Bayes \n",
    "* with more samples and the best performing hyperparameters from above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXVnZr18Hy1j"
   },
   "outputs": [],
   "source": [
    "mnb = MultinomialNB(alpha = 1.0)\n",
    "mnb.fit(X_train, y_train)\n",
    "train_preds = mnb.predict(X_train)\n",
    "preds = mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2FYCBZzpHy1j",
    "outputId": "a6917ee5-4d88-4bef-c9f3-a39f5dd87c8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 50.76\n",
      "Test F1 Score: 49.23\n"
     ]
    }
   ],
   "source": [
    "# Testing Score\n",
    "score = metrics.f1_score(y_test, preds, average = 'micro')\n",
    "\n",
    "# Training Score\n",
    "score_train = metrics.f1_score(y_train, train_preds, average = 'micro')\n",
    "\n",
    "print(f'Training F1 Score: {round(score_train * 100, 2)}')\n",
    "print(f'Test F1 Score: {round(score * 100, 2)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJ0eaVNLHy1k"
   },
   "source": [
    "# Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_GZq3-LHy1k"
   },
   "outputs": [],
   "source": [
    "# log_reg = LogisticRegression(solver = 'liblinear')\n",
    "# log_reg.fit(X_train, y_train)\n",
    "# train_preds = log_reg.predict(X_train)\n",
    "# preds = mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qf7JVL41Hy1k",
    "outputId": "5f25a9b2-3c69-430d-bb6c-09063386e99f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 54.92\n",
      "Test F1 Score: 49.23\n"
     ]
    }
   ],
   "source": [
    "# # Testing Score\n",
    "# score = metrics.f1_score(y_test, preds, average = 'micro')\n",
    "\n",
    "# # Training Score\n",
    "# score_train = metrics.f1_score(y_train, train_preds, average = 'micro')\n",
    "\n",
    "# print(f'Training F1 Score: {round(score_train * 100, 2)}')\n",
    "# print(f'Test F1 Score: {round(score * 100, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNGEDYFWHy1k"
   },
   "source": [
    "# Bootstrap Imbalanced Classes\n",
    "\n",
    "#### SMOTE \n",
    "\n",
    "\"SMOTE stands for **Synthetic Minority Oversampling Technique.** This is a statistical technique for **increasing the number of cases in your dataset in a balanced way.** The module works by generating new instances from existing minority cases that you supply as input. This implementation of SMOTE does not change the number of majority cases.\n",
    "\n",
    "The **new instances are not just copies** of existing minority cases; instead, the algorithm takes samples of the feature space for each target class and its nearest neighbors, and generates new examples that combine features of the target case with features of its neighbors. This approach increases the features available to each class and makes the samples more general.\n",
    "\n",
    "SMOTE takes the entire dataset as an input, but it increases the percentage of only the minority cases. For example, suppose you have an imbalanced dataset where just 1% of the cases have the target value A (the minority class), and 99% of the cases have the value B. To increase the percentage of minority cases to twice the previous percentage, you would enter 200 for SMOTE percentage in the module's properties.\"\n",
    "\n",
    "* https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/smote#:~:text=SMOTE%20stands%20for%20Synthetic%20Minority,dataset%20in%20a%20balanced%20way.&text=SMOTE%20takes%20the%20entire%20dataset,of%20only%20the%20minority%20cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbOoa83sHy1l"
   },
   "outputs": [],
   "source": [
    "def smote_oversample(x, y):\n",
    "\n",
    "    # Instantiate Oversampler\n",
    "    oversample = SMOTE()\n",
    "    \n",
    "    # fit oversampler\n",
    "    x, y = oversample.fit_resample(x, y)\n",
    "    \n",
    "    # Counter creates a dict that summarizes the distribution\n",
    "    counter = Counter(y)\n",
    "\n",
    "    for key, value in counter.items():\n",
    "        \n",
    "        # create variable with percentage of samples of each variable \n",
    "        percent = round(value / len(y_train) * 100, 2)\n",
    "        \n",
    "    # create df of target labels\n",
    "    ovr_sampled = pd.DataFrame(counter.keys(), columns = ['target_label'])\n",
    "    # append number of samples to df\n",
    "    ovr_sampled['num_samples'] = counter.values()\n",
    "    # append percentage of samples to df\n",
    "    ovr_sampled['percent'] = percent\n",
    "\n",
    "    plt.bar(ovr_sampled['target_label'], ovr_sampled['percent'])\n",
    "    \n",
    "    plt.title('Class Labels as Percentage of Samples')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Percentage of Labels')\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show(); \n",
    "    \n",
    "    # return df of sample distributions\n",
    "    print(ovr_sampled)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "id": "5HkfUVW3Hy1l",
    "outputId": "5f9c5751-301c-49e2-afcc-0c20741ea1e7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          target_label  num_samples  percent\n",
      "0      Sauvignon Blanc        10183    20.63\n",
      "1   Cabernet Sauvignon        10183    20.63\n",
      "2               Merlot        10183    20.63\n",
      "3           Sangiovese        10183    20.63\n",
      "4          Tempranillo        10183    20.63\n",
      "5             Riesling        10183    20.63\n",
      "6           Pinot Noir        10183    20.63\n",
      "7             Nebbiolo        10183    20.63\n",
      "8           Chardonnay        10183    20.63\n",
      "9                Syrah        10183    20.63\n",
      "10      Gewurztraminer        10183    20.63\n",
      "11        Pinot Grigio        10183    20.63\n",
      "12              Malbec        10183    20.63\n",
      "13           Zinfandel        10183    20.63\n",
      "14           Garganega        10183    20.63\n",
      "15    Gruner Veltliner        10183    20.63\n",
      "16            Viognier        10183    20.63\n",
      "17            Albarino        10183    20.63\n",
      "18               Glera        10183    20.63\n",
      "19            Grenache        10183    20.63\n",
      "20        Chenin Blanc        10183    20.63\n"
     ]
    }
   ],
   "source": [
    "XS_train, ys_train = smote_oversample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjRUd6HlHy1l"
   },
   "outputs": [],
   "source": [
    "smote_mnb = MultinomialNB(alpha = 1.0)\n",
    "smote_mnb.fit(XS_train, ys_train)\n",
    "train_preds = smote_mnb.predict(XS_train)\n",
    "preds = smote_mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqlqfRL8Hy1l",
    "outputId": "23fa739d-70e4-453c-9813-ab5a2daaca29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 38.77\n",
      "Test F1 Score: 44.19\n"
     ]
    }
   ],
   "source": [
    "# Testing Score\n",
    "score = metrics.f1_score(y_test, preds, average = 'micro')\n",
    "\n",
    "# Training Score\n",
    "score_train = metrics.f1_score(ys_train, train_preds, average = 'micro')\n",
    "\n",
    "print(f'Training F1 Score: {round(score_train * 100, 2)}')\n",
    "print(f'Test F1 Score: {round(score * 100, 2)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8h83XzSBHy1m"
   },
   "outputs": [],
   "source": [
    "smote_log_reg = LogisticRegression(solver = 'liblinear')\n",
    "smote_log_reg.fit(XS_train, ys_train)\n",
    "train_preds = smote_mnb.predict(XS_train)\n",
    "preds = smote_mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KdQT6VjOHy1m",
    "outputId": "1e94373b-07b8-4ad5-d515-f21536c9ece3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 38.77\n",
      "Test F1 Score: 44.19\n"
     ]
    }
   ],
   "source": [
    "# Testing Score\n",
    "score = metrics.f1_score(y_test, preds, average = 'micro')\n",
    "\n",
    "# Training Score\n",
    "score_train = metrics.f1_score(ys_train, train_preds, average = 'micro')\n",
    "\n",
    "print(f'Training F1 Score: {round(score_train * 100, 2)}')\n",
    "print(f'Test F1 Score: {round(score * 100, 2)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XMFZEw_GSvu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of 003_downsample_grid.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
