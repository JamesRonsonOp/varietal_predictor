{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "# About The Cab_Pinot Notebook\n",
    "_______\n",
    "\n",
    "* This notebook initially takes in a fully preprocessed csv with all observations and no accounting for imbalance. Another dataframe is then created that slices out observations where the value is either `Cabernet Sauvignon` or `Pinot Noir` in the `varietal` column.\n",
    "\n",
    "* Target and predictor variables are created from this dataframe, a baseline model is prepared and quickly analyzed, the df is split into training and testing sets, vectorized and then fit for modeling. \n",
    "\n",
    "* I fit three different models here based on the performance of the 20 class multiclassifier on this dataset. Random Forest, Logistic Regression and Multinomial Naive Bayes. \n",
    "\n",
    "* After this initial modeling I then run all three models after applying Synthetic Minority Oversampling Technique (SMOTE). \n",
    "\n",
    "**Summary of Results**\n",
    "\n",
    "SMOTE had a largely insiginificant effect on overall F1 Score. The only model that benefitted from SMOTE was Logistic Regression which saw no increase in its test score but saw it go from slightly overfit to neither under or overfit. \n",
    "\n",
    "____\n",
    "## Table of Contents\n",
    "____\n",
    "\n",
    "\n",
    "* [Baseline Model](#baseline)\n",
    "* [Random Forest Model](#random)\n",
    "* [Multinomial Naive Bayes](#mnb)\n",
    "* [Logistic Regression](#log_reg)\n",
    "* [Boostrapped Multinomial Naive Bayes](#bootstrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUcwDaHHHy0t",
    "outputId": "92e03474-399e-46fc-c8a2-1cacad29ea24"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importing Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# SKLearn Libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# SKLearn Model Libraries\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# SKLearn Metric Libraries\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "from sklearn.metrics import roc_curve, plot_roc_curve, auc, f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# Other Libraries\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from random import sample\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QclIwFDdHy0v"
   },
   "source": [
    "_______\n",
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "id": "QZmcTJNxHy0w"
   },
   "outputs": [],
   "source": [
    "# wine_df = pd.read_csv('/Users/jamesopacich/Documents/dsi/projects/capstone_archive/data/preprocessed_ready_4_model.csv') \n",
    "wine_df = pd.read_csv('../data/003_preprocessed_all_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "Vav626KVHy0x",
    "outputId": "b44c7e56-6910-428c-af8a-509f06cc9402"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varietal</th>\n",
       "      <th>description</th>\n",
       "      <th>color</th>\n",
       "      <th>parsed</th>\n",
       "      <th>parsed_w_stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Riesling</td>\n",
       "      <td>pineapple rind lemon pith blossom start bit op...</td>\n",
       "      <td>white</td>\n",
       "      <td>pineapple rind lemon pith and orange blossom s...</td>\n",
       "      <td>pineapple rind lemon pith blossom start bit op...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   varietal                                        description  color  \\\n",
       "0  Riesling  pineapple rind lemon pith blossom start bit op...  white   \n",
       "\n",
       "                                              parsed  \\\n",
       "0  pineapple rind lemon pith and orange blossom s...   \n",
       "\n",
       "                                      parsed_w_stops  \n",
       "0  pineapple rind lemon pith blossom start bit op...  "
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "varietal          0\n",
       "description       6\n",
       "color             0\n",
       "parsed            0\n",
       "parsed_w_stops    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "varietal          0\n",
       "description       0\n",
       "color             0\n",
       "parsed            0\n",
       "parsed_w_stops    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabernet Sauvignon    15197\n",
       "Pinot Noir            12192\n",
       "Name: varietal, dtype: int64"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cab_pinot = wine_df[(wine_df['varietal'] == 'Cabernet Sauvignon') | (wine_df['varietal'] == 'Pinot Noir')]\n",
    "cab_pinot['varietal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>varietal</th>\n",
       "      <th>parsed_w_stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25930</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>regular comes tannic rustic earthy herbal char...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25931</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>supple plum envelopes oaky structure supported...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25932</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>slightly reduced chalky tannic explosion accen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25936</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>sleek hint widely available neutral staved ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25938</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>intermingle robust floor designated hails bodi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27384</th>\n",
       "      <td>73653</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>result bodied firm structure leather plum espr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27385</th>\n",
       "      <td>73655</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>bodied firm tannins soften vanilla cassis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27386</th>\n",
       "      <td>73656</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>acidity hinting toasty future moment aging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27387</th>\n",
       "      <td>73657</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>cranberry clove anisette espresso bean hint cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27388</th>\n",
       "      <td>73658</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>given decade means cellared drinking baked coc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27389 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index            varietal  \\\n",
       "0      25930          Pinot Noir   \n",
       "1      25931  Cabernet Sauvignon   \n",
       "2      25932  Cabernet Sauvignon   \n",
       "3      25936          Pinot Noir   \n",
       "4      25938          Pinot Noir   \n",
       "...      ...                 ...   \n",
       "27384  73653  Cabernet Sauvignon   \n",
       "27385  73655  Cabernet Sauvignon   \n",
       "27386  73656          Pinot Noir   \n",
       "27387  73657  Cabernet Sauvignon   \n",
       "27388  73658          Pinot Noir   \n",
       "\n",
       "                                          parsed_w_stops  \n",
       "0      regular comes tannic rustic earthy herbal char...  \n",
       "1      supple plum envelopes oaky structure supported...  \n",
       "2      slightly reduced chalky tannic explosion accen...  \n",
       "3      sleek hint widely available neutral staved ind...  \n",
       "4      intermingle robust floor designated hails bodi...  \n",
       "...                                                  ...  \n",
       "27384  result bodied firm structure leather plum espr...  \n",
       "27385          bodied firm tannins soften vanilla cassis  \n",
       "27386         acidity hinting toasty future moment aging  \n",
       "27387  cranberry clove anisette espresso bean hint cr...  \n",
       "27388  given decade means cellared drinking baked coc...  \n",
       "\n",
       "[27389 rows x 3 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cab_pinot = cab_pinot[['varietal','parsed_w_stops']]\n",
    "cab_pinot.reset_index(inplace = True)\n",
    "cab_pinot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "cab_pinot.to_csv('../data/cab_pinot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Evwnhq0vHy1C"
   },
   "source": [
    "__________\n",
    "# Create Target and Predictor Variables\n",
    "_________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "id": "sK6_E6UyHy1L"
   },
   "outputs": [],
   "source": [
    "X = cab_pinot['parsed_w_stops']\n",
    "# Creating Multi-Class Targets\n",
    "y = cab_pinot['varietal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "id": "n00fDTzaHy1M"
   },
   "outputs": [],
   "source": [
    "# Binarizing binary targets\n",
    "y = y.map({'Pinot Noir': 0, 'Cabernet Sauvignon': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CQz2Tj6XHy1N",
    "outputId": "1259a92c-bedc-4d7e-afb7-ea7f862f8dfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Variables Shape: (27389,)\n",
      "Target Variables Shape: (27389,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Feature Variables Shape: {X.shape}')\n",
    "print(f'Target Variables Shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQyRxdo9Hy1O"
   },
   "source": [
    "<a id='baseline'></a>\n",
    "________\n",
    "# Baseline Model\n",
    "* Randomly guessing a varietal would choose the positive class, Cabernet Sauvignon, 55% of the time and the negative class, Pinot Noir 45% of the time. \n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2NMn-epYHy1P",
    "outputId": "abf8955e-6a61-404d-85cd-59581a62f1f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.554858\n",
       "0    0.445142\n",
       "Name: varietal, dtype: float64"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o996cf4JHy1R"
   },
   "source": [
    "# Train / Test / Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "id": "iKp4UQ1IHy1R"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size = .33, \n",
    "                                                   stratify = y, \n",
    "                                                   random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WZUs4ZkHy1f"
   },
   "source": [
    "# Vectorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoMdZOjOHy1f"
   },
   "source": [
    "{'clf': RandomForestClassifier(min_samples_split=5, n_estimators=50), 'vect__max_df': 0.8, 'vect__max_features': 500, 'vect__ngram_range': (1, 3), 'vect__stop_words': None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvaTlcIBHy1f",
    "outputId": "ee545554-6cd6-481a-e7b4-7a0693909014"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_df=0.8, max_features=500, ngram_range=(1, 3))"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate CountVectorizer()\n",
    "cvec = CountVectorizer(max_df = .8, max_features = 500, \n",
    "                       ngram_range = (1,3))\n",
    "\n",
    "# fit CountVectorizer()\n",
    "cvec.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "id": "XGmewI2BHy1g"
   },
   "outputs": [],
   "source": [
    "# Transform the corpus on training data\n",
    "X_train = cvec.transform(X_train)\n",
    "X_test = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59g76X_vHy1e"
   },
   "source": [
    "<a id='random'></a>\n",
    "_____\n",
    "# Random Forest\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tXVnZr18Hy1j"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-460453192344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mforest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_samples_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(min_samples_split = 5, n_estimators = 50)\n",
    "forest.fit(X_train, y_train)\n",
    "train_preds = forest.predict(X_train)\n",
    "preds = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2FYCBZzpHy1j",
    "outputId": "a6917ee5-4d88-4bef-c9f3-a39f5dd87c8f"
   },
   "outputs": [],
   "source": [
    "# Testing Score\n",
    "score = metrics.f1_score(y_test, preds, average = 'binary')\n",
    "\n",
    "# Training Score\n",
    "score_train = metrics.f1_score(y_train, train_preds, average = 'binary')\n",
    "\n",
    "print(f'Training F1 Score: {round(score_train * 100, 2)}')\n",
    "print(f'Test F1 Score: {round(score * 100, 2)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mnb'></a>\n",
    "________\n",
    "# Multinomial Naive Bayes\n",
    "_______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB(alpha = 1.0)\n",
    "mnb.fit(X_train, y_train)\n",
    "train_preds = mnb.predict(X_train)\n",
    "preds = mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 81.05\n",
      "Test F1 Score: 80.52\n"
     ]
    }
   ],
   "source": [
    "# Testing Score\n",
    "score = metrics.f1_score(y_test, preds, pos_label = 1, average = 'binary')\n",
    "\n",
    "# Training Score\n",
    "score_train = metrics.f1_score(y_train, train_preds, pos_label = 1, average = 'binary')\n",
    "\n",
    "print(f'Training F1 Score: {round(score_train * 100, 2)}')\n",
    "print(f'Test F1 Score: {round(score * 100, 2)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### Pickling MNB for use in Streamlit\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model in pickle format and storing it as 'mnb_red_clf.pkl'\n",
    "pickle_out = open('../06_streamlit/mnb_red_clf.pkl', mode = 'wb')\n",
    "\n",
    "# sending mnb model to 'pickle_out' \n",
    "pickle.dump(mnb, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJ0eaVNLHy1k"
   },
   "source": [
    "<a id='log_reg'></a>\n",
    "________\n",
    "# Logisitic Regression\n",
    "_______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "id": "I_GZq3-LHy1k"
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(solver = 'liblinear')\n",
    "log_reg.fit(X_train, y_train)\n",
    "train_preds = log_reg.predict(X_train)\n",
    "preds = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "id": "qf7JVL41Hy1k",
    "outputId": "5f25a9b2-3c69-430d-bb6c-09063386e99f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 82.88\n",
      "Test F1 Score: 81.0\n"
     ]
    }
   ],
   "source": [
    "# Testing Score\n",
    "score = metrics.f1_score(y_test, preds, pos_label = 1, average = 'binary')\n",
    "\n",
    "# Training Score\n",
    "score_train = metrics.f1_score(y_train, train_preds, pos_label = 1, average = 'binary')\n",
    "\n",
    "print(f'Training F1 Score: {round(score_train * 100, 2)}')\n",
    "print(f'Test F1 Score: {round(score * 100, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNGEDYFWHy1k"
   },
   "source": [
    "<a id='bootstrap'></a>\n",
    "______\n",
    "# Bootstrap Imbalanced Classes\n",
    "_____\n",
    "\n",
    "#### SMOTE \n",
    "\n",
    "\"SMOTE stands for **Synthetic Minority Oversampling Technique.** This is a statistical technique for **increasing the number of cases in your dataset in a balanced way.** The module works by generating new instances from existing minority cases that you supply as input. This implementation of SMOTE does not change the number of majority cases.\n",
    "\n",
    "The **new instances are not just copies** of existing minority cases; instead, the algorithm takes samples of the feature space for each target class and its nearest neighbors, and generates new examples that combine features of the target case with features of its neighbors. This approach increases the features available to each class and makes the samples more general.\n",
    "\n",
    "SMOTE takes the entire dataset as an input, but it increases the percentage of only the minority cases. For example, suppose you have an imbalanced dataset where just 1% of the cases have the target value A (the minority class), and 99% of the cases have the value B. To increase the percentage of minority cases to twice the previous percentage, you would enter 200 for SMOTE percentage in the module's properties.\"\n",
    "\n",
    "* https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/smote#:~:text=SMOTE%20stands%20for%20Synthetic%20Minority,dataset%20in%20a%20balanced%20way.&text=SMOTE%20takes%20the%20entire%20dataset,of%20only%20the%20minority%20cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qbOoa83sHy1l"
   },
   "outputs": [],
   "source": [
    "def smote_oversample(x, y):\n",
    "\n",
    "    # Instantiate Oversampler\n",
    "    oversample = SMOTE()\n",
    "    \n",
    "    # fit oversampler\n",
    "    x, y = oversample.fit_resample(x, y)\n",
    "    \n",
    "    # Counter creates a dict that summarizes the distribution\n",
    "    counter = Counter(y)\n",
    "\n",
    "    for key, value in counter.items():\n",
    "        \n",
    "        # create variable with percentage of samples of each variable \n",
    "        percent = round(value / len(y_train) * 100, 2)\n",
    "        \n",
    "    # create df of target labels\n",
    "    ovr_sampled = pd.DataFrame(counter.keys(), columns = ['target_label'])\n",
    "    # append number of samples to df\n",
    "    ovr_sampled['num_samples'] = counter.values()\n",
    "    # append percentage of samples to df\n",
    "    ovr_sampled['percent'] = percent\n",
    "\n",
    "    plt.bar(ovr_sampled['target_label'], ovr_sampled['percent'])\n",
    "    \n",
    "    plt.title('Class Labels as Percentage of Samples')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Percentage of Labels')\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show(); \n",
    "    \n",
    "    # return df of sample distributions\n",
    "    print(ovr_sampled)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "id": "5HkfUVW3Hy1l",
    "outputId": "5f9c5751-301c-49e2-afcc-0c20741ea1e7",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-de382b00782b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mXS_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote_oversample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "XS_train, ys_train = smote_oversample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### MNB with SMOTE\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "id": "wjRUd6HlHy1l"
   },
   "outputs": [],
   "source": [
    "smote_mnb = MultinomialNB(alpha = 1.0)\n",
    "smote_mnb.fit(XS_train, ys_train)\n",
    "train_preds = smote_mnb.predict(XS_train)\n",
    "preds = smote_mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqlqfRL8Hy1l",
    "outputId": "23fa739d-70e4-453c-9813-ab5a2daaca29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 78.71\n",
      "Test F1 Score: 79.94\n"
     ]
    }
   ],
   "source": [
    "# Testing Score\n",
    "score = metrics.f1_score(y_test, preds, average = 'binary')\n",
    "\n",
    "# Training Score\n",
    "score_train = metrics.f1_score(ys_train, train_preds, average = 'binary')\n",
    "\n",
    "print(f'Training F1 Score: {round(score_train * 100, 2)}')\n",
    "print(f'Test F1 Score: {round(score * 100, 2)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "id": "8h83XzSBHy1m"
   },
   "outputs": [],
   "source": [
    "smote_log_reg = LogisticRegression(solver = 'liblinear')\n",
    "smote_log_reg.fit(XS_train, ys_train)\n",
    "train_preds = smote_log_reg.predict(XS_train)\n",
    "preds = smote_log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KdQT6VjOHy1m",
    "outputId": "1e94373b-07b8-4ad5-d515-f21536c9ece3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 80.37\n",
      "Test F1 Score: 79.06\n"
     ]
    }
   ],
   "source": [
    "# Testing Score\n",
    "score = metrics.f1_score(y_test, preds, average = 'binary')\n",
    "\n",
    "# Training Score\n",
    "score_train = metrics.f1_score(ys_train, train_preds, average = 'binary')\n",
    "\n",
    "print(f'Training F1 Score: {round(score_train * 100, 2)}')\n",
    "print(f'Test F1 Score: {round(score * 100, 2)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "id": "1XMFZEw_GSvu"
   },
   "outputs": [],
   "source": [
    "smote_forest = RandomForestClassifier(min_samples_split = 5, n_estimators = 50)\n",
    "smote_forest.fit(XS_train, ys_train)\n",
    "train_preds = forest.predict(XS_train)\n",
    "preds = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 95.6\n",
      "Test F1 Score: 80.91\n"
     ]
    }
   ],
   "source": [
    "# Testing Score\n",
    "score = metrics.f1_score(y_test, preds, average = 'binary')\n",
    "\n",
    "# Training Score\n",
    "score_train = metrics.f1_score(ys_train, train_preds, average = 'binary')\n",
    "\n",
    "print(f'Training F1 Score: {round(score_train * 100, 2)}')\n",
    "print(f'Test F1 Score: {round(score * 100, 2)}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of 003_downsample_grid.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
